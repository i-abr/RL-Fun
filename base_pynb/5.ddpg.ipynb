{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:26:55.361673Z",
     "start_time": "2019-04-27T21:26:55.032415Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import roboschool\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:26:55.501855Z",
     "start_time": "2019-04-27T21:26:55.363066Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:26:55.507156Z",
     "start_time": "2019-04-27T21:26:55.503338Z"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Replay Buffer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:26:55.516065Z",
     "start_time": "2019-04-27T21:26:55.508694Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normalize action space</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:26:55.525133Z",
     "start_time": "2019-04-27T21:26:55.517888Z"
    }
   },
   "outputs": [],
   "source": [
    "class NormalizedActions(gym.ActionWrapper):\n",
    "\n",
    "    def _action(self, action):\n",
    "        low_bound   = self.action_space.low\n",
    "        upper_bound = self.action_space.high\n",
    "        \n",
    "        action = low_bound + (action + 1.0) * 0.5 * (upper_bound - low_bound)\n",
    "        action = np.clip(action, low_bound, upper_bound)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def _reverse_action(self, action):\n",
    "        low_bound   = self.action_space.low\n",
    "        upper_bound = self.action_space.high\n",
    "        \n",
    "        action = 2 * (action - low_bound) / (upper_bound - low_bound) - 1\n",
    "        action = np.clip(action, low_bound, upper_bound)\n",
    "        \n",
    "        return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Ornstein-Uhlenbeck process</h2>\n",
    "Adding time-correlated noise to the actions taken by the deterministic policy<br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process\">wiki</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:26:55.533711Z",
     "start_time": "2019-04-27T21:26:55.527115Z"
    }
   },
   "outputs": [],
   "source": [
    "class OUNoise(object):\n",
    "    def __init__(self, action_space, mu=0.0, theta=0.15, max_sigma=0.3, min_sigma=0., decay_period=100000):\n",
    "        self.mu           = mu\n",
    "        self.theta        = theta\n",
    "        self.sigma        = max_sigma\n",
    "        self.max_sigma    = max_sigma\n",
    "        self.min_sigma    = min_sigma\n",
    "        self.decay_period = decay_period\n",
    "        self.action_dim   = action_space.shape[0]\n",
    "        self.low          = action_space.low\n",
    "        self.high         = action_space.high\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = np.ones(self.action_dim) * self.mu\n",
    "        \n",
    "    def evolve_state(self):\n",
    "        x  = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(self.action_dim)\n",
    "        self.state = x + dx\n",
    "        return self.state\n",
    "    \n",
    "    def get_action(self, action, t=0):\n",
    "        ou_state = self.evolve_state()\n",
    "        self.sigma = self.max_sigma - (self.max_sigma - self.min_sigma) * min(1.0, t / self.decay_period)\n",
    "        return np.clip(action + ou_state, self.low, self.high)\n",
    "    \n",
    "#https://github.com/vitchyr/rlkit/blob/master/rlkit/exploration_strategies/ou_strategy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:26:55.542716Z",
     "start_time": "2019-04-27T21:26:55.535696Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Continuous control with deep reinforcement learning</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1509.02971\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:26:55.556397Z",
     "start_time": "2019-04-27T21:26:55.544642Z"
    }
   },
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = F.elu(self.linear1(x))\n",
    "        x = F.elu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "from torch.autograd.gradcheck import zero_gradients\n",
    "def compute_jacobian(inputs, output):\n",
    "    \"\"\"\n",
    "    :param inputs: Batch X Size (e.g. Depth X Width X Height)\n",
    "    :param output: Batch X Classes\n",
    "    :return: jacobian: Batch X Classes X Size\n",
    "    \"\"\"\n",
    "    assert inputs.requires_grad\n",
    "\n",
    "    num_classes = output.size()[1]\n",
    "\n",
    "    jacobian = torch.zeros(num_classes, *inputs.size())\n",
    "    grad_output = torch.zeros(*output.size())\n",
    "    if inputs.is_cuda:\n",
    "        grad_output = grad_output.cuda()\n",
    "        jacobian = jacobian.cuda()\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        zero_gradients(inputs)\n",
    "        grad_output.zero_()\n",
    "        grad_output[:, i] = 1\n",
    "        output.backward(grad_output, retain_graph=True)\n",
    "        jacobian[i] = inputs.grad.data\n",
    "\n",
    "    return torch.transpose(jacobian, dim0=0, dim1=1)\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_states, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_states = num_states\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_states + num_actions, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, num_states)\n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def jac(self, x):\n",
    "        y = self.forward(Variable(x, requires_grad=True))\n",
    "        out = []\n",
    "        for _ in range(self.num_states):\n",
    "            pass\n",
    "        pass \n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "            \n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, num_actions)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.elu(self.linear1(state))\n",
    "        x = F.elu(self.linear2(x))\n",
    "        x = torch.tanh(self.linear3(x))\n",
    "        return x\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state  = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        action = self.forward(state)\n",
    "        return action.detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>DDPG Update</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:26:55.566415Z",
     "start_time": "2019-04-27T21:26:55.557945Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def ddpg_update(batch_size, \n",
    "           gamma = 0.99,\n",
    "           min_value=-np.inf,\n",
    "           max_value=np.inf,\n",
    "           soft_tau=1e-1):\n",
    "    \n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "    \n",
    "    state      = torch.FloatTensor(state).to(device)\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    action     = torch.FloatTensor(action).to(device)\n",
    "    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "    done       = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(device)\n",
    "    dx         = next_state - state\n",
    "    \n",
    "    policy_loss = value_net(state, policy_net(state))\n",
    "    policy_loss = -policy_loss.mean()\n",
    "\n",
    "    next_action    = target_policy_net(next_state)\n",
    "    target_value   = target_value_net(next_state, next_action.detach())\n",
    "    expected_value = reward + (1.0 - done) * gamma * target_value\n",
    "#     expected_value = torch.clamp(expected_value, min_value, max_value)\n",
    "\n",
    "    value = value_net(state, action)\n",
    "    value_loss = value_criterion(value, expected_value.detach())\n",
    "    \n",
    "    model_loss = model_criterion(dx, model_net(torch.cat([state, action],1)))\n",
    "    \n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "\n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "    \n",
    "    model_optimizer.zero_grad()\n",
    "    model_loss.backward()\n",
    "    model_optimizer.step()\n",
    "\n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "            )\n",
    "\n",
    "    for target_param, param in zip(target_policy_net.parameters(), policy_net.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "            )\n",
    "    return model_loss.item(), value_loss.item(), policy_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:26:55.582897Z",
     "start_time": "2019-04-27T21:26:55.568023Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Environment '<class 'roboschool.gym_pendulums.RoboschoolInvertedPendulumSwingup'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "# env_name = \"RoboschoolInvertedPendulum-v1\"\n",
    "env_name = \"RoboschoolInvertedPendulumSwingup-v1\"\n",
    "# env_name = \"RoboschoolHalfCheetah-v1\"\n",
    "# env_name = \"HalfCheetah-v3\"\n",
    "env = NormalizedActions(gym.make(env_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:26:55.582897Z",
     "start_time": "2019-04-27T21:26:55.568023Z"
    }
   },
   "outputs": [],
   "source": [
    "ou_noise = OUNoise(env.action_space, theta=0.4)\n",
    "\n",
    "state_dim  = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "hidden_dim = 128\n",
    "policy_hidden_dim = 128\n",
    "model_hidden_dim = 200\n",
    "\n",
    "\n",
    "value_net  = ValueNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "policy_net = PolicyNetwork(state_dim, action_dim, policy_hidden_dim).to(device)\n",
    "model_net = Model(state_dim, action_dim, model_hidden_dim).to(device)\n",
    "\n",
    "target_value_net  = ValueNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "target_policy_net = PolicyNetwork(state_dim, action_dim, policy_hidden_dim).to(device)\n",
    "\n",
    "for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "\n",
    "for target_param, param in zip(target_policy_net.parameters(), policy_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "    \n",
    "    \n",
    "value_lr  = 1e-3\n",
    "policy_lr = 1e-3\n",
    "model_lr = 1e-3\n",
    "\n",
    "value_optimizer  = optim.SGD(value_net.parameters(),  lr=value_lr, momentum=0.9)\n",
    "policy_optimizer = optim.SGD(policy_net.parameters(), lr=policy_lr,momentum=0.9)\n",
    "# model_optimizer  = optim.SGD(model_net.parameters(), lr=model_lr, momentum=0.9)\n",
    "model_optimizer  = optim.Adam(model_net.parameters(), lr=model_lr)\n",
    "# value_optimizer  = optim.Adam(value_net.parameters(),  lr=value_lr )\n",
    "# policy_optimizer = optim.Adam(policy_net.parameters(), lr=policy_lr)\n",
    "\n",
    "value_criterion = nn.MSELoss()\n",
    "model_criterion = nn.MSELoss()\n",
    "\n",
    "replay_buffer_size = 1000000\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:26:55.587503Z",
     "start_time": "2019-04-27T21:26:55.584566Z"
    }
   },
   "outputs": [],
   "source": [
    "max_frames  = 20000\n",
    "max_steps   = 200\n",
    "frame_idx   = 0\n",
    "rewards     = []\n",
    "model_losses= []\n",
    "policy_losses= []\n",
    "\n",
    "batch_size  = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:28:18.321590Z",
     "start_time": "2019-04-27T21:26:55.589322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-626414afdec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddpg_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mmodel_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mpolicy_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1b4f7a9ae79e>\u001b[0m in \u001b[0;36mddpg_update\u001b[0;34m(batch_size, gamma, min_value, max_value, soft_tau)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#     expected_value = torch.clamp(expected_value, min_value, max_value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mvalue_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-71c9defa38e8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36melu\u001b[0;34m(input, alpha, inplace)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while frame_idx < max_frames:\n",
    "    state = env.reset()\n",
    "    ou_noise.reset()\n",
    "    episode_reward = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        action = policy_net.get_action(state)\n",
    "        action = ou_noise.get_action(action, step)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        done = False\n",
    "        env.render()\n",
    "        replay_buffer.push(state, action, reward, next_state, done)\n",
    "        if len(replay_buffer) > batch_size:\n",
    "            model_loss, value_loss, policy_loss = ddpg_update(batch_size)\n",
    "            model_losses.append(model_loss)\n",
    "            policy_losses.append(policy_loss)\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % max(1000, max_steps + 1) == 0:\n",
    "            plot(frame_idx, rewards)\n",
    "#             plot(frame_idx, policy_losses)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    rewards.append(episode_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T21:28:18.323755Z",
     "start_time": "2019-04-27T21:26:55.086Z"
    }
   },
   "outputs": [],
   "source": [
    "    state = env.reset()\n",
    "    ou_noise.reset()\n",
    "    episode_reward = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        action = policy_net.get_action(state)\n",
    "#         action = ou_noise.get_action(action, step)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.FloatTensor([1,2]), requires_grad=True)\n",
    "y = torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.backward([y],[torch.FloatTensor([[0,1]])], retain_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd.gradcheck import zero_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jacobian(inputs, output):\n",
    "    \"\"\"\n",
    "    :param inputs: Batch X Size (e.g. Depth X Width X Height)\n",
    "    :param output: Batch X Classes\n",
    "    :return: jacobian: Batch X Classes X Size\n",
    "    \"\"\"\n",
    "    assert inputs.requires_grad\n",
    "\n",
    "    num_classes = output.size()[1]\n",
    "\n",
    "    jacobian = torch.zeros(num_classes, *inputs.size())\n",
    "    grad_output = torch.zeros(*output.size())\n",
    "    if inputs.is_cuda:\n",
    "        grad_output = grad_output.cuda()\n",
    "        jacobian = jacobian.cuda()\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        zero_gradients(inputs)\n",
    "        grad_output.zero_()\n",
    "        grad_output[:, i] = 1\n",
    "        output.backward(grad_output, retain_graph=True)\n",
    "        jacobian[i] = inputs.grad.data\n",
    "\n",
    "    return torch.transpose(jacobian, dim0=0, dim1=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.FloatTensor([[1,2]]), requires_grad=True)\n",
    "y = torch.sin(x)\n",
    "%timeit compute_jacobian(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jacobian(net, x, noutputs):\n",
    "    x = x.squeeze()\n",
    "    n = x.size()[0]\n",
    "    x = x.repeat(noutputs, 1)\n",
    "    x.requires_grad_(True)\n",
    "    y = net(x)\n",
    "    y.backward(torch.eye(noutputs))\n",
    "return x.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.FloatTensor([[1,2]]), requires_grad=True)\n",
    "# x = torch.FloatTensor([1,2])\n",
    "x = x.squeeze()\n",
    "x = x.repeat(2, 1)\n",
    "M = torch.FloatTensor([[0.1,0],[0,0.1]])\n",
    "# x.requires_grad_(True)\n",
    "y = torch.sin(torch.mm(x, M))\n",
    "y.backward(torch.eye(2), retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jacobian(net, x, noutputs):\n",
    "    x = x.squeeze()\n",
    "    n = x.size()[0]\n",
    "    x = x.repeat(noutputs, 1)\n",
    "    x.requires_grad_(True)\n",
    "    y = net(x)\n",
    "    y.backward(torch.eye(noutputs))\n",
    "    return x.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.FloatTensor(state).to(device).unsqueeze(0)\n",
    "inputs = Variable(inputs, requires_grad=True)\n",
    "out = policy_net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit compute_jacobian(inputs, out)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
