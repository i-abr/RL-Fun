{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T17:22:14.033677Z",
     "start_time": "2019-04-29T17:22:13.721030Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import roboschool\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T17:22:14.186308Z",
     "start_time": "2019-04-29T17:22:14.035320Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T17:22:14.208061Z",
     "start_time": "2019-04-29T17:22:14.188417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T17:22:14.266241Z",
     "start_time": "2019-04-29T17:22:14.210147Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Environment '<class 'roboschool.gym_pendulums.RoboschoolInvertedPendulum'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Environment '<class 'roboschool.gym_pendulums.RoboschoolInvertedPendulum'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Environment '<class 'roboschool.gym_pendulums.RoboschoolInvertedPendulum'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Environment '<class 'roboschool.gym_pendulums.RoboschoolInvertedPendulum'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Environment '<class 'roboschool.gym_pendulums.RoboschoolInvertedPendulum'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Environment '<class 'roboschool.gym_pendulums.RoboschoolInvertedPendulum'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Environment '<class 'roboschool.gym_pendulums.RoboschoolInvertedPendulum'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Environment '<class 'roboschool.gym_pendulums.RoboschoolInvertedPendulum'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/anon/src/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Environment '<class 'roboschool.gym_pendulums.RoboschoolInvertedPendulum'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "Process Process-7:\n",
      "Process Process-8:\n",
      "Process Process-1:\n",
      "Process Process-6:\n",
      "Process Process-5:\n",
      "Process Process-2:\n",
      "Process Process-3:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anon/sand_box/personal-projects/rl-fun/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/anon/sand_box/personal-projects/rl-fun/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/anon/sand_box/personal-projects/rl-fun/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/anon/sand_box/personal-projects/rl-fun/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/anon/sand_box/personal-projects/rl-fun/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/anon/sand_box/personal-projects/rl-fun/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/anon/sand_box/personal-projects/rl-fun/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/anon/sand_box/personal-projects/rl-fun/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 8\n",
    "env_name = \"RoboschoolInvertedPendulum-v1\"\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T17:22:14.276911Z",
     "start_time": "2019-04-29T17:22:14.269034Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "        \n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T17:22:14.287082Z",
     "start_time": "2019-04-29T17:22:14.279653Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    for _ in range(400):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        if done: break\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T17:22:14.296116Z",
     "start_time": "2019-04-29T17:22:14.288310Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Proximal Policy Optimization Algorithm</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1707.06347\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T17:22:14.304594Z",
     "start_time": "2019-04-29T17:22:14.297791Z"
    }
   },
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            dist, value = model(state)\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_probs = dist.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T17:22:16.431457Z",
     "start_time": "2019-04-29T17:22:14.306721Z"
    }
   },
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 128\n",
    "lr               = 3e-4\n",
    "num_steps        = 200\n",
    "mini_batch_size  = 100\n",
    "ppo_epochs       = 4\n",
    "threshold_reward = 380\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T17:22:16.435145Z",
     "start_time": "2019-04-29T17:22:16.432918Z"
    }
   },
   "outputs": [],
   "source": [
    "max_frames = 15000\n",
    "frame_idx  = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T17:22:58.632170Z",
     "start_time": "2019-04-29T17:22:16.436570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8aa15729e257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mtest_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mtest_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-8aa15729e257>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mtest_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mtest_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9df8a4968f51>\u001b[0m in \u001b[0;36mtest_env\u001b[0;34m(vis)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    rewards   = []\n",
    "    masks     = []\n",
    "    entropy = 0\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_reward = np.mean([test_env(False) for _ in range(num_envs)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(frame_idx, test_rewards)\n",
    "            if test_reward > threshold_reward: early_stop = True\n",
    "            \n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    advantage = returns - values\n",
    "    \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Saving trajectories for GAIL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T17:22:58.634390Z",
     "start_time": "2019-04-29T17:22:13.760Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "max_expert_num = 50000\n",
    "num_steps = 0\n",
    "expert_traj = []\n",
    "\n",
    "for i_episode in count():\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        action = dist.sample().cpu().numpy()[0]\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        expert_traj.append(np.hstack([state, action]))\n",
    "        num_steps += 1\n",
    "    \n",
    "    print(\"episode:\", i_episode, \"reward:\", total_reward)\n",
    "    \n",
    "    if num_steps >= max_expert_num:\n",
    "        break\n",
    "        \n",
    "expert_traj = np.stack(expert_traj)\n",
    "print()\n",
    "print(expert_traj.shape)\n",
    "print()\n",
    "np.save(\"expert_traj.npy\", expert_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
